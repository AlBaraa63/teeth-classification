# ğŸ¦· The Teeth Classification Journey

> _A documentation of learning, building, and discovering through a real-world medical imaging project_

---

## ğŸ“– Chapter 1: The Beginning - Understanding the Mission

**The Problem:** We were given a challenging task - classify different types of tooth diseases using deep learning. A real dataset, real medical images, and a real-world problem to solve.

**The Goal:** Build an AI that can look at dental images and identify what's wrong - from cavities to oral cancer.

But here's the thing about machine learning - you can't just jump into coding. That's where most beginners fail.

---

## ğŸ”¬ Chapter 2: Research First, Code Later

### The Research Phase

Before writing a single line of code, we dove into research. The inspiration? The legendary **"ImageNet Classification with Deep Convolutional Neural Networks"** paper - the one that changed computer vision forever.

> **Key Insight:** Research is not optional. It's the foundation. Nearly 60-70% of a successful ML project is understanding what came before you.

### Where We Explored

We didn't just randomly Google things. We went to the sources where real researchers publish:

```
ğŸ”— HuggingFace Papers (Trending Research)
   https://huggingface.co/papers/trending

ğŸ”— ArXiv (Academic Papers Repository)
   https://arxiv.org/
```

**Why these sites?** Because this is where cutting-edge research lives. Reading papers isn't just about copying code - it's about understanding _why_ things work.



---

## ğŸ’¡ Chapter 3: Key Discoveries - What We Learned

### Discovery #1: ReLU - The Gatekeeper Function

While diving through papers, we kept seeing one thing over and over: **ReLU (Rectified Linear Unit)**

**What is it?**
Think of ReLU as a bouncer at a club. If the signal is positive (VIP), it lets it through. If it's negative or zero, it stops it cold.

```python
# The simplest powerful function in deep learning
ReLU(x) = max(0, x)

# Examples:
ReLU(5)   â†’ 5   âœ“ (Let it through!)
ReLU(-3)  â†’ 0   âœ— (Blocked!)
ReLU(0)   â†’ 0   âœ— (Blocked!)
```

**Why does this matter for our teeth classifier?**

1. **Non-linearity:** Without it, our neural network would just be fancy linear regression - useless for complex patterns like "is this tooth diseased?"
2. **Computational Efficiency:** It's just a comparison. Super fast. CNNs have millions of these, so speed matters.
3. **Gradient Flow:** Solves the "vanishing gradient" problem that killed older networks.

**The Gatekeeper Analogy:**
- Each neuron in our network decides: "Is this feature important?"
- ReLU says: "If yes (positive), pass it forward. If no (negative), kill it."
- This is how the network learns: cavity edges might activate neurons, healthy tissue might not.

ğŸ“º **Resource:** [ReLU Explained Visually (YouTube)](https://www.youtube.com/watch?v=6MmGNZsA5nI)

---



## ğŸ¯ Our Learning Philosophy

We're not building this by copying tutorials. We're learning by doing it right.

```
ğŸ“š Understand the Concept
    â†“
ğŸ¤” Why does this matter for teeth classification?
    â†“
ğŸ’» Write the code ourselves
    â†“
ğŸ“Š See the results visualized
    â†“
âœ… Learn from what worked (or didn't)
```

---

## ğŸ—ï¸ Chapter 4: Building the Foundation

### Step 0: Project Architecture

Before any AI magic happens, we need a clean workspace. Think of this like organizing a lab before an experiment.

```
teeth-classification/
â”‚
â”œâ”€â”€ ğŸ“ data/                    â† Our patient images live here
â”‚   â”œâ”€â”€ Training/               â† Learn from these
â”‚   â”œâ”€â”€ Validation/             â† Check our progress
â”‚   â””â”€â”€ Testing/                â† Final exam
â”‚
â”œâ”€â”€ ğŸ“ src/                     â† The brain of our project
â”‚   â”œâ”€â”€ dataset.py              â† Loads and prepares images
â”‚   â”œâ”€â”€ model.py                â† The CNN architecture (our AI doctor)
â”‚   â”œâ”€â”€ train.py                â† Teaching loop (where learning happens)
â”‚   â”œâ”€â”€ evaluate.py             â† Test the trained model
â”‚   â”œâ”€â”€ visualize.py            â† Show us what's happening
â”‚   â”œâ”€â”€ test_augmentation.py    â† Prove augmentation works
â”‚   â””â”€â”€ test_gpu.py             â† Check GPU availability
â”‚
â”œâ”€â”€ ğŸ“ outputs/                 â† Save our results
â”‚   â”œâ”€â”€ *.png                   â† Charts and visualizations
â”‚   â””â”€â”€ *.pth                   â† Trained model checkpoints
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt         â† Dependencies
â”œâ”€â”€ ğŸ“„ README.MD                â† Project overview
â””â”€â”€ ğŸ“„ learning outcome.md      â† This file â€” our journey
```

### The Tools We Need

```txt
torch          â† The deep learning engine
torchvision    â† Computer vision tools
matplotlib     â† Visualization and plots
numpy          â† Number crunching
pillow         â† Image processing
tqdm           â† Progress bars (sanity saver)
```

**Why these specifically?**
- **PyTorch:** Industry standard, flexible, great for research
- **matplotlib:** We need to see what our AI sees
- **tqdm:** Training takes hours - we need progress bars for our sanity



---

## ğŸ” Chapter 5: Meeting Our Data - The First Look

> **Rule #1 of Machine Learning:** Never write code before you understand your data. Ever.

Most people skip this. They jump straight to "training a model." Then they wonder why it fails.

We won't make that mistake.

### The Questions We Must Answer

Before we train anything, we need to know:

```
â“ How many images do we have per disease?
â“ Is the dataset balanced or will our AI be biased?
â“ What do these dental images actually look like?
â“ What are their dimensions and quality?
â“ Are there patterns we can spot with human eyes?
```

### ğŸ“Š What We Discovered

After exploring the dataset, here's what we found:

| Disease Type | Code | Sample Count | Status | Notes |
|-------------|------|--------------|--------|-------|
| **Oral Lichen Planus** | OLP | 540 | ğŸŸ¢ Largest | Autoimmune condition |
| **Mouth Cancer** | MC | 540 | ğŸŸ¢ Largest | Most critical to detect |
| **Calculus** | CaS | 480 | ğŸŸ¢ Good | Tartar buildup |
| **Caries** | CoS | 450 | ğŸŸ¢ Good | Cavities |
| **Oral Trauma** | OT | 393 | ğŸŸ¡ Medium | Injuries/damage |
| **Gum Disease** | Gum | 360 | ğŸŸ  Smaller | Periodontal issues |
| **Oral Candidiasis** | OC | 324 | ğŸ”´ Smallest | Fungal infection |

**Total Training Images:** ~3,087

### ğŸ¯ Key Insights

1. **Relatively Balanced:** No class is dramatically underrepresented (largest is only 1.67x smallest)
2. **Real-World Distribution:** This mirrors actual clinical frequency - some conditions are rarer
3. **Challenge Ahead:** The smaller classes (OC, Gum) might be harder to learn
4. **Medical Importance:** Cancer and Lichen Planus have the most data - that's good, they're critical

### What This Means for Our Model

| Finding | Implication |
|---------|-------------|
| ~3,000 images | Medium-sized dataset â€” augmentation is essential |
| Slight imbalance | We'll use weighted loss or monitor per-class accuracy |
| 256Ã—256 size | Resize to 224Ã—224 (standard) for our CNN |
| Medical images | Be careful with augmentation â€” don't distort diagnostic features |

### Visualization

<img src="outputs/sample_images.png" alt="Sample Images" width="600">
<img src="outputs/class_distribution.png" alt="Class Distribution" width="600">



---

## ğŸš€ Chapter 6: Preprocessing & Augmentation

> **The AlexNet Lesson:** "Artificially increased training data by flipping, cropping, and color-shifting images. Reduced overfitting without collecting more data."

With only ~3,000 images, our model would memorize the training data (overfit) instead of actually learning. This is where **data augmentation** comes in â€” a trick we learned straight from the AlexNet paper.

### Understanding Transforms

In PyTorch, we use `torchvision.transforms` to preprocess images. There are two types:

| Type | Purpose | Examples |
|------|---------|----------|
| **Deterministic** | Always produces the same output | Resize, Normalize |
| **Random** | Changes each time (augmentation) | RandomFlip, RandomRotation |

**The Rule:**
- **Training:** Use both deterministic and random transforms (augmentation helps the model generalize)
- **Validation / Testing:** Use **only deterministic** transforms (we need consistent, fair evaluation)

### Our Transformation Pipeline

We built a pipeline that takes each image through a series of steps before the model ever sees it:

<img src="outputs/transform_pipeline_steps.png" alt="Transformation Pipeline Steps" width="600">

### The Power of Normalization

One important discovery was **normalization** â€” scaling pixel values so the network trains faster and more stably. Instead of raw pixel values (0-255), we shift them to a range centered around zero using ImageNet statistics.

> **Why does this help?** Think of it like converting all measurements to the same unit before doing math. It makes the network's job easier.

<img src="outputs/normalization_explained.png" alt="Normalization Explained" width="600">

### Augmentation in Action

Here's what our augmented images look like compared to the originals â€” same tooth, different perspectives:

<img src="outputs/augmentation_comparison.png" alt="Augmentation Comparison" width="600">

The model now sees each image in dozens of variations: flipped, rotated, color-shifted. This effectively multiplies our dataset many times over.

---

## ğŸ§  Chapter 7: Understanding CNNs - The Detective Analogy

Now we arrive at the heart of the project: **building the actual neural network**. But before writing any code, we needed to understand _how_ a CNN actually "sees."

### A CNN Thinks Like a Detective

Imagine you're a detective trying to identify a tooth condition from a photo. You don't look at the whole image at once. Instead:

1. **First**, you notice basic things: edges, colors, dark spots
2. **Then**, you combine those into shapes: is this a tooth? is this gum?
3. **Then**, you look for patterns: texture of decay, color of infection
4. **Finally**, you decide: "This looks like Mouth Cancer"

A CNN works exactly the same way â€” layer by layer, building up from simple features to complex understanding.

### Our CNN Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        YOUR TOOTH IMAGE                            â”‚
â”‚                         224 Ã— 224 Ã— 3                              â”‚
â”‚                      (RGB color image)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      BLOCK 1          â”‚
                    â”‚  "Find basic edges"   â”‚
                    â”‚   112Ã—112Ã—32 output   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      BLOCK 2          â”‚
                    â”‚  "Find textures"      â”‚
                    â”‚    56Ã—56Ã—64 output    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      BLOCK 3          â”‚
                    â”‚  "Find patterns"      â”‚
                    â”‚   28Ã—28Ã—128 output    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      BLOCK 4          â”‚
                    â”‚  "Find conditions"    â”‚
                    â”‚   14Ã—14Ã—256 output    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  GLOBAL AVG POOL      â”‚
                    â”‚   256 numbers         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  DROPOUT + LINEAR     â”‚
                    â”‚   7 class scores      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  PREDICTION: "MC" ğŸ¦·    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each block uses the same pattern we learned about: **Conv â†’ BatchNorm â†’ ReLU â†’ MaxPool**. The deeper we go, the more abstract the features become â€” from raw edges to actual disease patterns.

### What the Model Actually Sees

This is one of the most fascinating parts. We visualized what each block detects, and you can see the progression from edges to full patterns:

<img src="outputs/feature_maps.png" alt="Feature Maps at Each Block" width="600">

> **Key Insight:** The early layers detect universal features (edges, colors) that could apply to any image. The deeper layers learn teeth-specific patterns â€” this is where the real "intelligence" lives.

---

## ğŸ‹ï¸ Chapter 8: Training - Teaching the Model

### What is "Training"?

Training a neural network is like teaching a child to identify animals:

```
TRAINING LOOP (simplified):

1. Show image     â†’ "What do you think this is?"
2. Model guesses  â†’ "Umm... Calculus?"
3. Check answer   â†’ "No, it's Mouth Cancer"
4. Calculate mistake â†’ "You were 70% wrong"
5. Adjust brain   â†’ Model updates its internal numbers
6. Repeat 1000s of times...
7. Eventually     â†’ Model gets good at it!
```

### The 3 Key Components

| Component | What It Does | Analogy |
|-----------|-------------|---------|
| **Loss Function** | Measures how wrong the guess was | "You scored 3/10 on this quiz" |
| **Optimizer** | Decides how to adjust weights | "Study chapter 5 more next time" |
| **Training Loop** | Repeats the process | "Practice every single day" |

We chose **CrossEntropyLoss** (standard for classification) and **Adam optimizer** (adaptive learning rate â€” it figures out _how much_ to adjust each weight).

### How Our Code Fits Together

```
dataset.py          model.py
    â”‚                   â”‚
    â”‚ (provides data)   â”‚ (provides structure)
    â”‚                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
       train.py
            â”‚
            â”‚ (uses both to train)
            â”‚
            â–¼
    trained_model.pth
            â”‚
            â”‚ (saved weights)
            â”‚
            â–¼
      evaluate.py
```

Each file has a clear responsibility. `dataset.py` feeds the images, `model.py` defines the brain, and `train.py` orchestrates the learning process. Clean separation â€” just like a real lab.

---

## ğŸ“ˆ Chapter 9: The Results - From 57% to 97.67%

This is where the story gets exciting.

### First Attempt: The Baseline

We fired up the GPU (verified with `test_gpu.py`), ran our simple CNN for just 2 epochs as a quick sanity check, and got our first result:

**57% accuracy.**

Not terrible for a first try with 7 classes (random guessing would give ~14%), but far from useful in a medical context.

<img src="outputs/training_history1.png" alt="First Training History" width="600">

### The Optimization Journey

Instead of accepting mediocrity, we asked: _what can we improve?_ Here's what we changed:

```
BEFORE (Baseline):                    AFTER (Improved):
â”œâ”€â”€ Simple CNN (4 blocks)             â”œâ”€â”€ ResNet-style CNN (skip connections!)
â”œâ”€â”€ 20 epochs                         â”œâ”€â”€ 50 epochs
â”œâ”€â”€ Fixed learning rate               â”œâ”€â”€ Learning rate decreases when stuck
â””â”€â”€ Result: ~57% accuracy             â”œâ”€â”€ Early stopping (saves time)
                                      â””â”€â”€ Expected: 65-75% accuracy
```

The biggest change was adding **residual (skip) connections** â€” inspired by the ResNet paper. Instead of each layer learning everything from scratch, skip connections let information flow directly through the network. Think of it like building a highway alongside local roads â€” traffic flows much better.

We also added:
- **Learning rate scheduler:** Automatically reduces the learning rate when the model stops improving
- **Early stopping:** If the model hasn't improved in 10 epochs, stop wasting time
- **More training time:** 50 epochs instead of 20 (with early stopping as a safety net)

### The Result: 97.67% Validation Accuracy

After training the improved model, we were stunned. The validation accuracy shot up to **97.67%**.

<img src="outputs/training_history2.png" alt="Improved Training History" width="600">

> **What happened?** The skip connections solved the gradient vanishing problem. The scheduler prevented overshooting. And early stopping saved us from overfitting. Every optimization worked together.

### Per-Class Performance

But overall accuracy can be misleading. We needed to check: _does the model perform well on every disease, or just the common ones?_

<img src="outputs/per_class_accuracy.png" alt="Per-Class Accuracy" width="600">

### Sample Predictions

And finally â€” seeing the model in action, making real predictions on images it has never seen before:

<img src="outputs/sample_predictions.png" alt="Sample Predictions" width="600">

Green borders mean correct. Red borders mean mistakes. The model correctly identifies tooth conditions with high confidence â€” even distinguishing between visually similar diseases.

---

## ğŸ¯ Chapter 10: Reflections - What We Learned

Looking back at this journey, the biggest lessons weren't about code:

1. **Research before code.** Reading the AlexNet and ResNet papers shaped every decision we made â€” from augmentation to skip connections.
2. **Understand your data.** That first exploration of the dataset (Chapter 5) revealed the class imbalance and informed our training strategy.
3. **Start simple, then improve.** Our baseline CNN showed us what was possible. The improved version showed us what was achievable.
4. **Every component matters.** It wasn't one magic trick that took us from 57% to 97.67% â€” it was the combination of better architecture, smarter training, and proper preprocessing.

> **Final Thought:** Machine learning is not about building the most complex model. It's about understanding the problem deeply enough to make the right decisions at every step.

---

**Status:** ğŸŸ¢ Complete
_Last Updated: 2026-01-30_



